---
sidebar_position: 2  # 菜单中的排序位置（1 表示第一个）
slug: /whitepaper              # 文档访问路径（/ 表示首页）
sidebar_label: "白皮书"  # 左侧菜单显示的名称（自定义你想要的文字）
---
import Viewer from '@/components/Viewer'; // 引入自定义组件

<Viewer imgUrl="/img/logo.png" />

# **Vcity.ai 白皮书**

⾯向全球的去中⼼化AI算⼒⽹络平台

**第五城科技**

版本：v1.1.0

首次发布于 2025 年 10 月 27 日；最近更新于 2025 年 11 月 28 日

:::

# 摘要

Vcity.ai作为一个去中心化AI算力基础设施网络（DePIN），旨在解决当前AI行业面临的算力垄断和供需失衡问题。该平台的核心价值在于整合全球闲置GPU资源，通过区块链技术实现算力资源的去中心化调度、透明结算和公平分配，为企业和个人提供低成本、高弹性的AI算力服务。Vcity.ai系统采用三层架构设计：基于可信公链的基础层、基础GPU组成的算力层和提供上层服务的应用层。通过高效可信计算验证，分布式任务的弹性调度，机密私有模型和多重激励机制作为我们的核心竞争力从而确保网络的稳定运行和服务质量。Vcity.ai的经济体系构建于一个核心的设计哲学之上：将网络的日常商业运营与长期价值投资进行分离。为此，协议采用了双轨资产框架。网络内的所有核心业务均使用稳定币进行计价与结算。同时发行代币VCAI作为价值捕获与治理代币，捕获网络的可持续性收入的可持续性和治理决定网络发展方向。

Vcity.ai提供三大核心服务：（1）AI算力服务（IaaS），支持大规模模型训练和推理；（2）AI解决方案服务（PaaS），为文旅、教育等垂直行业提供定制化服务；（3）AI智能体服务（AaaS），实现AI及其衍生内容的资产化和自由交易。从而致力于构建一个开放、公平、高效的去中心化AI生态系统。

# 一、行业背景与趋势

## 1.1 生成式人工智能推动算力需求爆炸式增长

随着生成式人工智能（GenAI）技术的快速发展，其模型规模正经历着前所未有的扩张。无论是开源还是闭源模型，其参数规模都呈现出指数级增长趋势，从最初的亿级参数跃升至如今的万亿级规模。以最新发布的模型为例，开源领域的DeepSeek V3.2已达到671B参数规模，而闭源模型GPT-4的参数量更是高达1.7T。

这种参数规模的急剧扩张直接带来了对计算资源的巨大需求。以DeepSeek V3.2为例，在FP16推理（含KV缓存）设定下，显存需求约在1.3-1.5TB量级，这相当于需要数十块GPU协同工作才能支撑模型的推理运算。这种对GPU资源近乎贪婪的需求，不仅推高了AI应用的部署成本，也加剧了全球范围内高性能计算资源的供需矛盾。

## 1.2 云计算服务的成本与局限性

当前，云基础设施提供商已经承载了全球互联网流量的50%以上，成为数字经济的重要基础设施。然而，传统云计算模式在应对AI时代的挑战时暴露出诸多问题。

首先，云服务定价机制复杂且成本高昂，对于需要长期、大规模使用GPU资源的AI应用而言，运营成本往往难以承受。其次，主流云服务商通过专有API、特定工具链等手段构建封闭生态系统，导致客户在技术选型上受到限制，难以灵活迁移或采用多云策略。 在地理分布方面，云数据中心往往集中部署在能源成本和土地成本较低的区域，这种集中化部署模式难以满足边缘计算和实时AI应用对低延迟的严苛要求。此外，云服务在资源调度透明度、定制化配置等方面的不足，也限制了其在特定场景下的应用价值。

## 1.3 算力资源分配的结构性失衡

面对云服务的种种局限，大型企业和研究机构纷纷投入巨资自建数据中心，以期获得更好的性能控制、数据安全保障和成本效益。这种趋势催生了一场全球性的“算力军备竞赛”，各方都在争相囤积GPU等高性能计算资源。

然而，这种发展模式带来了严重的资源分配不均问题。头部科技企业凭借雄厚的资本实力大量采购和囤积GPU资源，在AI模型训练和部署上建立了难以逾越的竞争优势。与此同时，中小型AI研发团队、初创企业以及Web3领域的开发者却面临着“一卡难求”的困境，即使能够获得GPU资源，其成本也往往超出预算承受能力。

这种算力资源的高度集中化不仅加剧了AI生态系统的“马太效应”，使得强者愈强、弱者愈弱，更重要的是，它严重限制了技术创新的多样性和包容性。大量具有创新潜力的中小团队因缺乏算力支撑而无法将创意转化为实际应用，整个AI产业的创新活力受到抑制。

# 二、Vcity.ai 平台

## 2.1 解决方案

针对当前人工智能产业在算力供需、资源集中度以及成本结构方面存在的系统性失衡，Vcity.ai提出了一种基于去中心化技术的新型算力基础设施方案。其核心理念是通过可信区块链网络与分布式计算架构，将全球范围内的闲置GPU资源进行智能聚合与调度，从而构建一个开放、高效且可持续的AI算力生态。

Vcity.ai的设计目标在于打破传统云计算模式的封闭与垄断，实现算力的“去中心化供给、按需分配与可验证使用”。平台通过技术层面的可信激励机制，使个人、机构或数据中心的闲置算力都能够被纳入全球统一的调度网络，并在无需信任中介的前提下，为AI开发者、企业及机构提供高性能计算服务。

与传统云模式相比，Vcity.ai在成本、弹性和透明度上具有显著优势：

1. 成本可控：按需计费与自动竞价机制有效降低GPU使用门槛；
2. 性能弹性：分布式调度系统可根据任务负载进行动态资源扩缩容；
3. 可信透明：区块链确保算力使用过程的可追溯性与结果可验证性。

此外，Vcity.ai并非仅是算力网络的再造，而是一个覆盖“基础设施-解决方案-智能服务”全栈的AI生态系统。平台分别通过IaaS、PaaS与AaaS三层服务体系，为不同类型用户提供从算力供给、AI应用开发到智能体交易的完整技术闭环，从根本上重塑AI产业的资源配置方式与价值流通模式。

## 2.2 平台概述

Vcity.ai是基于可信公链构建的去中心化AI算力基础设施网络（DePIN），旨在从根本上解决当前人工智能行业面临的算力资源集中垄断与供需失衡问题。平台将全球范围内的闲置GPU资源进行有效整合，构建了一个具备高弹性、高性能和低延迟特性的分布式AI计算服务网络。其主要包含以下三项服务。

### 2.2.1 AI 算⼒服务（Infrastructure-as-a-service, IaaS)

为AI企业、Web3项⽬⽅等提供灵活的裸GPU调⽤服务，⽀持⼤模型微调、部署、推理、云渲染等典型任务负载。

- LLM微调与部署容器：提供预配置的训练环境，集成PyTorch、TensorFlow等主流框架，支持LoRA等高效微调技术，实现模型的快速迭代和优化部署。
- 人工智能生成内容（AIGC）生成容器：内置Stable Diffusion等主流生成模型，通过负载均衡和并发优化技术，支持高吞吐量的文本、图像、音频等多模态内容生成任务。
- 云渲染与实时视觉容器：专门针对虚拟现实、增强现实和3D应用场景优化，提供毫秒级延迟的实时渲染服务，支持高分辨率输出和光线追踪等先进渲染技术。
- 企业级定制容器：提供完全隔离的私有计算环境，支持自定义配置、专用API接口和企业级SLA保障，满足金融、医疗等行业的合规性要求。

### 2.2.2 AI ⽅案解决服务（Platform-as-a-service, PaaS）

⾯向⽂旅、教育、博物馆、体育等终端领域用户，构建集内容创作、智能交互、知识传播与⽂化资产活化于⼀体的⼀站式AI应⽤服务和⽅案解决。

- 文旅行业数字化转型：部署AI虚拟导游系统，提供多语言实时讲解服务；构建数字人IP形象，打造沉浸式文化体验；运用计算机视觉技术实现文物智能识别与解读；通过大语言模型生成个性化文化故事内容，提升游客参与度和满意度。
- 教育场景智能化升级：基于学习行为分析实现个性化学习路径规划；提供7×24小时AI教辅答疑服务；自动生成差异化教学内容和练习题库；构建智能化的学习效果评估体系，助力教育公平和质量提升。
- 体育与赛事智能服务：部署实时AI解说系统，提供专业级赛事评论；运用计算机视觉进行运动数据采集与战术分析；构建AR/VR沉浸式观赛平台；生成个性化精彩集锦和数据报告。
- 政府与公益数字化应用：建设数字文化遗产保护平台，实现文化资源的永久保存；开发智能问答系统，提升公共服务效率；构建知识普及平台，促进信息公平获取；支持智慧城市和数字政府建设。

### 2.2.3 AI 智能交易服务（Agent-as-a-Service, AaaS）

面向开发者、内容创作者和行业客户，提供AI智能体的创建、部署、铸造、交易与调用等能力，实现基于AIGC的价值流通与商业变现。

- 一站式开发工具链：集成模型训练、优化、封装、测试、部署等全流程开发组件；提供可视化开发界面和代码模板库；支持主流AI框架和模型格式；内置性能监控和调试工具，确保智能体稳定运行。
- 算力即服务支持：无缝接入平台分布式GPU资源池，实现弹性算力调度；采用按需计费模式，大幅降低模型部署和运行成本；提供自动扩缩容机制，应对突发流量；支持边缘计算节点部署，满足低延迟需求。
- NFT化确权机制：通过智能合约将AI智能体铸造为唯一NFT资产；绑定开发者身份、版权信息和调用权限；建立透明的收益分配机制；支持智能体的版本管理和更新迭代；确保知识产权的有效保护。
- 丰富的交易与调用场景：支持智能体NFT的铸造、定价、上架和交易；提供灵活的授权模式（独占、共享、限时等）；覆盖文旅导览、智能客服、内容创作、数据分析等多元应用场景；建立用户评价和信誉体系，促进优质服务发现。

## 2.3 整体架构

Vcity.ai产品构建于可信公链之上，通过融合Web3与区块链技术的创新优势，构建了一个全球性的去中心化GPU算力基础设施网络。该网络旨在满足AI训练推理、实时渲染以及文旅垂直领域大模型等高性能计算场景的多样化需求。

整体架构采用分层设计理念，包含以下三层：

**基础信任层（可信公链）：**基于可信公链作为Layer-1，为Vcity.ai提供高速、安全、稳定的区块链基础设施，确保整个算力网络的可靠运行。同时依托其实现智能合约的自动化执行，支持算力服务的安全交易与实时结算，保障交易的透明性和不可篡改性。

**算力网络层（去中心化GPU节点网络）：**在可信公链之上Vcity.ai构建了一个去中心化的算力网络层。该层包括算力节点、验证节点和调度节点，三者通过协同工作实现算力资源的高效匹配和质量保障，从而聚合全球范围内分散的GPU资源节点，形成规模化、高效的算力网络池。

**应用接入层（API与DApp应用层）：**在算力网络层之上，Vcity.ai构建了一套完整的开发者工具生态，提供标准化的API接口、SDK及DApp应用框架，便于AI公司、游戏开发商和独立开发者快速接入并调用高性能算力资源和直观友好的资源管理界面与支付结算工具，简化操作流程，提升用户的整体使用体验。

<!-- ![Vcity.ai 产品架构](images/vcityai_product.png) -->

<Viewer imgUrl="/img/vcityai_product.png" />

## 2.4 算力网络层

去中心化的算力网络层由三类核心节点构成：**算力节点**作为核心组件提供实际的边缘化GPU算力资源；**验证节点**负责校验算力节点的运行状态，确保计算任务的真实准确完成；**调度节点**则负责任务的智能分配与资源优化。每个都拥有其唯一的链上身份标识（DID），用于节点信用评估、历史服务记录追溯和声誉系统构建，形成可信的去中心化算力生态。三者协同工作，共同构建高效可靠的分布式算力网络。

### 2.4.1 算力节点

#### *节点功能*

算力节点作为算力任务执行的基本单元，是网络中GPU算力的直接提供者，为AI训练、推理及实时渲染等高密度计算任务提供支撑。为满足不同用户的需求，Vcity.ai网络将节点设计为稳定节点与灵活节点两类。

#### *稳定节点*

稳定节点主要由可信的数据中心提供，是由高性能企业级 GPU 集群构成的长期、高可用的算力资源。其核心价值在于为需要长期、稳定、可信算力的任务（例如大模型的预训练与微调）提供坚实的基础设施支撑。

#### *灵活节点*

灵活节点由广泛的个人用户或边缘设备提供，具备高度的灵活性和分布式特性。此类节点构成了网络的弹性算力层，能够为突发性或周期性的计算任务（例如大模型的部署）提供大规模、近源、可快速部署的算力资源。

#### *技术要求*

- 硬件配置：节点需配备符合标准化配置的GPU。
- 注册机制：通过智能合约完成节点注册，自动记录节点类型、性能参数、GPU型号及质押信息。
- 状态监控：主动汇报节点状态，包括在线情况、算力负载和健康度等关键指标。

#### *质押机制*

每个算力节点需根据GPU规格、市场供需关系以及代币价值，质押相应数量的代币。质押参数由系统每周根据市场动态自动调整，确保经济模型的健康运转。

### 2.4.2 验证节点

#### *节点功能*

验证节点作为算力任务验证系统的核心，通过周期性抽查和基于证明的随机验证机制监督算力节点，验证GPU资源真实性、服务质量与节点表现，确保网络的诚信运行。同时，任何能成功提交合法的算力节点不良行为证明的节点都可以成为验证节点，形成去中心化的监督体系。

#### *验证机制*

- 质量追踪：通过数据流实时监控服务质量，跟踪节点表现的关键性能指标，包括响应延迟、任务成功率和交付质量。
- 开放准入：算力网络层中任何能成功提交合法的算力节点不良行为证明的节点都可以成为验证节点，形成去中心化的监督体系。

### 2.4.3 调度节点

#### *节点功能*

调度节点负责算力任务调度系统，采用微服务架构设计，处理客户提交的算力需求任务，自动分解并智能分发至最优算力节点。

#### *调度策略*

智能任务分配算法综合考虑以下因素：

- **网络延迟**：优先选择网络延迟较低的节点，确保任务执行效率
- **算力要求**：根据任务的计算复杂度匹配合适规格的GPU资源
- **价格因素**：在满足性能要求的前提下，选择成本最优的算力节点
- **服务质量**：参考历史服务记录，优先分配给高质量节点

通过上述多维度优化，实现资源利用最大化和用户体验最优化。

## 2.5 安全保障机制

为确保去中心化算力网络的安全性、可靠性和高效性，Vcity.ai平台构建了多层次的安全保障体系，涵盖可信计算验证、弹性调度管理以及经济激励等核心机制。

### 2.5.1 高效率的可信计算验证机制

Vcity.ai设计并实现了基于CPU可信执行环境的GPU计算验证框架。旨在以极低的性能开销，为GPU所执行的计算任务提供可信度证明。从而确保算力节点在去中心化AI推理等信任敏感型场景中计算过程的完整性与结果的正确性

### 2.5.2 分布式任务的弹性调度

Vcity.ai将集中式数据中心的算力与个人的灵活算力统一封装为对应的不可拆分算力执行单元。并依据调度算法，对于粒度、时长和成本敏感度各异的多样化任务，依据任务需求与资源状态的约束关系，实现算力任务的自动、优化分配。

### 2.5.3 私有模型机密保护

为满足企业对机密商业数据与私有模型的最高安全等级需求，我们提供了一套AI机密模型解决方案。 利用基于企业级可信计算平台，通过机密计算架构技术实现机密计算，配合行业标准加密算法加速与处理器内置的可信执行环境（TEE）技术，实现虚拟机内部端到端的加密计算。从而确保了从数据输入、模型处理到结果输出的全流程机密性，杜绝了节点运营方窃取用户隐私数据或模型资产的风险。

### 2.5.4 节点经济激励

平台设计了多层次的经济激励体系，旨在吸引高质量算力节点加入并保持长期稳定参与。

*算力证明：* 节点持续保持GPU资源在线状态，即使未被实际调用，仍可获得一定比例的基础奖励。奖励额度与节点在线时长、资源质量及稳定性正相关

*交付证明：* 根据节点完成实际算力服务的质量与数量，额外获得服务绩效奖励。服务质量优秀的节点将获得更高的经济回报和更优先的任务调度机会

*服务费激励：* 算力节点根据用户支付的算力服务费，获得相应比例的收益分成。节点资源品质越高、服务评价越好，服务费分成比例越高

*多卡集成激励机制：* 为优化大规模AI模型的训练效率，平台特别设计了多卡集成激励机制：

- 架构优化：鼓励节点运营者优先部署单机多卡架构，以提升整体吞吐率与调度效率
- 智能识别：系统自动识别节点机器的总显存容量，当单节点总显存达到特定阈值（如$\geq 96\ \text{GB}$）时，激励权重将呈阶梯式上浮
- 差异化激励：多卡节点将获得以下优势：

  - 更高的基础PoC奖励系数（最高可达1.5倍）
  - 调度优先级提升，获得更多高价值任务匹配机会
  - 参与高负载AI训练任务的独家资格

# 三、Vcity.ai（VCAI）代币经济模型

本章详细阐述了 Vcity.ai 网络的代币 VCAI 的经济模型。该模型旨在构建一个价值与网络基本面强绑定、治理结构去中心化、并能通过市场机制自我调节的、可持续发展的数字经济体。

Vcity.ai 的经济体系构建于一个核心的设计哲学之上：将网络的日常商业运营与长期价值投资进行分离。为此，协议采用了双轨资产框架：

- 支付资产：网络内的所有核心业务，如算力租赁、API 调用等，均使用稳定币进行计价与结算。这为用户和算力提供商创建了一个稳定、低摩擦的商业环境，规避了代币价格波动对核心业务成本的干扰。
- 权益资产：Vcity.ai Token（代币代码为VCAI）是 Vcity.ai 网络中唯一的价值捕获与治理代币，其核心价值来源于网络协议收入的可持续性和投票决定网络发展方向的治理权。

## 3.1 代币基本信息

VCAI 的定位是 Vcity.ai 网络的权益代币，代表了对网络生态的所有权。其持有者是网络的所有者，有权分享网络的增长红利并参与其治理决策。

### 3.1.1 代币基本信息

代币基本信息如下表所示：

| 项目         | 详情                         |
| ------------ | ---------------------------- |
| 代币名称     | Vcity.ai Token               |
| 代币代码     | VCAI                         |
| 发行公链     | Vcitychain                   |
| 初始总供应量 | 10,000,000,000（100亿）VCAI* |

\*注：此为协议创世时的供应量。协议内置一个由去中心化自治组织（DAO）治理控制的动态供应机制，以确保长期的激励可持续性和战略灵活性，详见下文。

### 3.1.2 代币分配与释放规则

本节所述的分配比例及释放计划，均基于100亿枚VCAI的初始供应量。其初始分配方案如下表所示。

| 代币分配       | 占比           | VCAI 数量                         | 解锁机制                                 | 用途                                                                                                       |
| -------------- | -------------- | --------------------------------- | ---------------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| 投资者（私募） | 23.5%          | 2,350,000,000（23.5亿）           | TGE：21.91%，根据融资细分                | 启动资金 + 资源整合                                                                                        |
| 投资者（公募） | 5.5%           | 550,000,000（5.5亿）              | TGE：30.91%，根据融资细分                | 启动资金 + 资源整合                                                                                        |
| 项目团队       | 20%            | 2,000,000,000（20亿）             | TGE：0%，18个月锁仓，TGE后42个月线性解锁 | 用于激励核心团队及高端人才，25%用于激励核心员工                                                            |
| 储备与治理基金 | 20%            | 2,000,000,000（20亿）             | -                                        | 由基金会管理，用于保障项目长期运营、战略合作、法律合规及应对突发状况，也包括社区开发者激励、生态项目扶持等 |
| 战略顾问       | 10%            | 1,000,000,000（10亿）             | TGE：0%，TGE后18个月线性解锁             | 吸引行业专家与生态伙伴长期参与项目建设、提供技术、品牌与战略资源支持                                       |
| 初始流动性     | 1%             | 100,000,000（1亿）                | TGE：100%                                | 提供买卖流动性                                                                                             |
| 生态激励池 *   | 20%            | 2,000,000,000（20亿）             | TGE：0%，TGE后10年线性释放               | 用于和10家左右的算力合作伙伴和拥有闲散GPU的提供者建立长期合作和网络激励                                    |
| **总量** | **100%** | **10,000,000,000（100亿）** | **7.85%**                          |                                                                                                            |

\* 生态激励池:具体分配由下文详述的“动态激励与治理模型”决定。

详细分配、锁仓与释放规则：

- 生态激励池 (20%)：用于驱动网络增长的长期激励，具体分配由下文详述的“动态激励与治理模型”决定。TGE：0%，自代币生成事件（TGE）后，在10年内按周期线性释放。
- 投资者 (29%)：

  - 投资者（私募）(23.5%)：分配给早期投资者。TGE：21.91%，剩余部分根据融资轮次的具体条款释放。
  - 投资者（公募）(5.5%)：分配给公募投资者。TGE：30.91%，剩余部分根据融资轮次的具体条款释放。
- 项目团队 (20%)：用于激励核心团队及高端人才。TGE：0%，18个月锁仓（Cliff），随后42个月线性解锁。
- 战略顾问 (10%)：激励行业专家与生态合作伙伴。TGE：0%，TGE后18个月线性解锁。
- 储备与治理基金 (20%)：由基金会管理，用于保障项目长期运营、战略合作、法律合规及应对突发状况。也包括社区开发者激励（Grants）及生态项目扶持等。
- 初始流动性 (1%)：在TGE时完全解锁（100%）。该额度专门用于在交易所和交易场所提供初始市场流动性，以保障代币的健康流通。

### 3.1.3 创世NFT

在TGE之前，为了凝聚和回馈最早期的社区用户，Vcity.ai将先行发售一套限量的“创世NFT”。这套NFT不仅是独特的数字收藏品，更是早期社区用户身份的象征与核心权益的凭证。其核心价值在于，每一枚创世NFT均绑定了在TGE后领取10,000VCAI代币空投的权益。

- 空投来源：空投代币将从“初始流动性”的分配额度中预先划拨，总计不超过初始流动性总量的30%。这一设计确保了对早期社区用户的回馈，是项目启动初期流动性策略的一个有机组成部分。
- 释放规则：为确保TGE后二级市场的健康与稳定，通过创世NFT领取的VCAI空投将遵循线性释放规则。具体来说，在TGE时可立即领取空投总额的25%，剩余75%在随后的6个月内逐月线性解锁。

## 3.2 投票托管治理模型

首先，为了确保网络的治理权与长期价值贡献者保持一致，协议引入了投票托管治理模型。该设计旨在筛选出网络的长期所有者（而非短期投机者）作为治理主体，从而保障决策的长期有效性。

其次，为了促进治理的去中心化，防止巨鲸（大额持币者）通过资本优势主导投票，我们引入平方投票法来调整投票权重的计算方式。新的权重将不再与锁仓的VCAI数量呈线性关系，而是亚线性关系。

### 3.2.1 权益凭证veVCAI

veVCAI（vote-escrowed VCAI）是 Vcity.ai 网络中的核心治理权益凭证，它并非一种新的代币，而是一个衡量用户锁仓贡献的动态权重。veVCAI 是所有治理投票和收益分配的唯一计算依据。

### 3.2.2 治理锁定机制

- 获取方式：用户通过在协议指定的智能合约中锁仓（Lock）VCAI 来获得 veVCAI 权重。锁仓是一项特定的链上行为，用户需自愿选择一个固定的、不可撤销的时间周期（如1个月或1年）。
- 权重计算：用户获得的veVCAI权重，与其锁仓的VCAI数量的$\alpha$次方和选择的锁仓时长呈正相关。其中$\alpha$设置为0.5，即平方根。这意味着持币量翻倍仅使投票权重增加约41%（$\sqrt{2}-1$），有效削弱大额资本对投票权重的绝对影响。
- 核心特性：

  - 不可转让性：veVCAI 权重本身不可在二级市场交易，杜绝了“治理权租赁”的风险。
  - 线性衰减：veVCAI 权重会随着锁仓到期日的临近而线性衰减。这一特性激励用户持续延长其锁仓周期，以维持其在网络中的治理影响力。

### 3.2.3 量化定义

| 参数             | 符号     | 定义                                       | 设定值                 |
| ---------------- | -------- | ------------------------------------------ | ---------------------- |
| 最大锁仓时长     | T_max    | 用户可以选择的最长锁仓时间                 | 4 年（126,230,400 秒） |
| 锁仓 VCAI 数量   | n_VCAI   | 用户锁仓的 VCAI 代币数量                   | 用户自定义             |
| 解锁时间戳       | t_unlock | 用户锁仓到期的未来时间戳（Unix Timestamp） | 用户自定义             |
| 当前时间戳       | t_now    | 当前的区块时间戳（Unix Timestamp）         | 动态变化               |
| 投票权重调节因子 | α       | 调节锁仓数量对投票权重影响的指数           | 0.5                    |

用户在任何时间点 $t_{\text{now}}$ 所拥有的 veVCAI 权重 $w_{\text{veVCAI}}$，由以下公式计算得出：

<!-- $$
w_{\text{veVCAI}}(t_{\text{now}}) = (n_{\text{VCAI}})^\alpha \cdot \frac{(t_{\text{unlock}} - t_{\text{now}})}{T_{\text{max}}},\ \text{s.t. } t_{\text{now}} \le t_{\text{unlock}}
$$ -->

<Viewer imgUrl="/img/vcai.png" />

这个公式确保了：

- 初始权重由锁仓数量和锁仓时长共同决定。
- 权重衰减与时间的流逝成正比，真实反映了剩余的承诺周期。

## 3.3 价值捕获模型

该模型的核心是建立一个将协议的商业成功与VCAI 代币的内在价值直接、自动且无信任地连接起来的桥梁。协议的所有收入都应服务于提升 VCAI 的价值，并以程序化的方式回馈给网络的长期所有者。

协议捕获的价值通过一个自动化的、透明的链上流程进行再分配：

1. 收入汇集：所有协议收入将被转移至一个专用的协议金库合约。
2. 市场回购：金库合约将以预设的时间周期（初始设定为每24小时），在公开的交易所上使用积累的收入执行 VCAI 代币的市场回购。此机制为 VCAI 提供了持续、透明且与网络业务量正相关的购买需求。
3. 权益分配：所有回购的 VCAI 将被直接发送至奖励分配合约。该合约根据所有用户的实时 veVCAI 权重，按区块将接收到的 VCAI 分配给所有 VCAI 的锁仓者。每个用户都可以随时通过协议接口领取（claim）自己当前已累积的奖励。

## 3.4 激励治理模型

为引导网络实现供需两端的健康平衡，并激励有益于生态的行为，模型设立了一个由veVCAI治理驱动、结合自动化调节的动态激励层。

### 3.4.1 激励来源

生态激励池的总量为 2,000,000,000 VCAI，全部用于激励治理模型，设计为期 10 年的线性释放。

| 概念         | 定义                         | 计算值                            |
| ------------ | ---------------------------- | --------------------------------- |
| 生态激励池   | 分配给生态激励池的 VCAI 总量 | 2,000,000,000 VCAI                |
| 释放总周期   | 生态基金的计划释放总时长     | 10 年（522 周）                   |
| 每周期释放量 | 每个激励周期释放的 VCAI 总量 | 3,831,417 VCAI，可由 DAO 投票调整 |

### 3.4.2 治理参数

网络的激励机制由社区共同决定。veVCAI持有者可以通过DAO治理投票，调整以下核心参数：

- 激励周期：每个激励分配和调整周期的时长。初始设定为每周，但DAO治理可投票调整为每日、每两周等。
- 周期释放数量：决定每个激励周期从“生态激励池”中释放的对应该周期的VCAI的百分比。初始设定为100%，但DAO治理可以投票降低此比例，将部分资金用于开发者Grants、生态合作等其他用途。

### 3.4.3 激励仪表盘：供需平衡机制

协议引入了一个自动化的供需平衡机制，旨在动态调节对算力供给方和需求方（消费方）的激励比例，使网络的算力利用率维持在一个健康的目标水平。

**核心指标参数。** 该机制围绕以下核心指标和协议内置的固定参数运行：

- 实际算力利用率：上一个激励周期内，全网被实际消耗的算力总量与可提供的算力总量的比率。这是一个客观反映网络繁忙程度的核心指标。表示为$U_{\text{actual}}$。

  <!-- $$
  U_{\text{actual}} = \frac{\text{周期内已消耗的算力单元}}{\text{周期内可提供的总算力单元}} \times 100\%
  $$ -->

  <Viewer imgUrl="/img/actual-zh.png" />
- 目标算力利用率：协议追求的最优算力利用率。该目标旨在确保网络高效运行，同时保留一定的冗余以应对突发需求。表示为$U_{\text{target}}$，设定值为80%。
- 调整系数：一个控制激励比例调整速度的敏感度系数，确保系统能够平稳地向目标收敛，避免剧烈波动。表示为$k$，设定值为0.1。
- 激励分配比例：分配给供给侧的激励比例表示为$P_{\text{supply}}$，分配给需求侧的激励比例表示为$P_{\text{demand}}$；两者之和为100%，即$P_{\text{supply}} + P_{\text{demand}} = 100\%$；两者初始值均设为50%。

**动态调整算法。** 在每个激励周期开始时，协议将根据上一个周期的 $U_{\text{actual}}$，自动更新本周期的供给侧激励比例 $P_{\text{supply}}$。计算公式如下：

<!-- $$
P_{\text{supply}}(t) = P_{\text{supply}}(t-1) + k \cdot \big(U_{\text{actual}}(t-1) - U_{\text{target}}\big)
$$ -->

<Viewer imgUrl="/img/supply.png" />

为避免越界，系统对 $P_{\text{supply}}(t)$ 与 $P_{\text{demand}}(t)$ 实施区间裁剪，确保二者始终位于 \[0%, 100%\] 且和为 100%。 其中，$P_{\text{supply}}(t)$ 为当前周期的供给侧激励比例；$P_{\text{supply}}(t-1)$ 为上一个周期的供给侧激励比例；$U_{\text{actual}}(t-1)$ 为上一个周期的实际算力利用率。

该机制是一个经典的负反馈控制系统。任何偏离目标利用率的情况都会触发反向的激励调整，自动将系统拉回平衡点，从而实现长期的自我稳定。敏感度系数 $k$ 的调节，使得激励比例的变化是渐进的、可预测的。这为算力提供者和消费者提供了稳定的市场预期，便于他们制定长期参与策略，避免了因突发性政策变化带来的市场冲击。

**情景演算。**

- 情况一：供给过剩

  - 假设上一周期 $U_{\text{actual}}$ 为 60%，低于 80% 的目标；
  - $P_{\text{supply}}$ 的变化 = 0.1 \* (60% - 80%) = -2%，即新的 $P_{\text{supply}}$ 将从上一周期的值降低2%；
  - 更多激励将流向需求侧（$P_{\text{demand}}$ 上升），通过补贴降低用户成本，从而刺激消费，提升算力利用率。
- 情况二：供给不足

  - 假设上一周期 $U_{\text{actual}}$ 为 95%，高于 80% 的目标；
  - $P_{\text{supply}}$ 的变化 = 0.1 \* (95% - 80%) = +1.5%，即新的 $P_{\text{supply}}$ 将从上一周期的值提高1.5%；
  - 更多激励将流向供给侧（$P_{\text{supply}}$ 上升），吸引更多算力提供者加入网络，增加总供给。

**激励分配。** 计算出当期的分配比例后，协议将按比例分配从“生态激励池”释放的总奖励。

- 对于供给侧激励池，这部分奖励将根据算力提供者的质押量、服务时长和稳定性等综合因素进行分配。
- 对于需求侧激励池，这部分奖励将作为一种消费补贴，根据用户在周期内的稳定币消费额按比例进行返还。

## 3.5 经济飞轮模型

<figure id="fig:flywheel_2">
<div class="minipage">
<!-- <img src="images/flywheel_1.png" /> -->
<Viewer imgUrl="/img/flywheel_1_zh.png" />
</div>
<div class="minipage">
<!-- <img src="images/flywheel_2.png" /> -->
<Viewer imgUrl="/img/flywheel_2_zh.png" />

</div>
</figure>



### 3.5.1 算力业务层经济飞轮

Vcity.ai 的代币经济学增长策略围绕三类核心参与者：算力使用者（应用开发方和终端用户）、算力提供者和投资者展开，目标是通过算力需求增长与代币机制联动，构建一个持续扩张的正向循环生态，如上图所示。

- 首先，随着更多算力提供者加入平台，算力供应不断增强。Vcity.ai 的激励机制确保节点即使在待机状态也能通过 PoC 容量证明获得基础代币收益，因此算力不会因闲置而无法变现。这一机制提高了节点加入和持续在线的意愿，而算力任务调用时长的增加又直接带来更高的代币奖励，使算力提供者的收益与代币价值同步提升。
- 与此同时，不断丰富的算力需求场景吸引了更多算力使用者进入生态。AI、云渲染、云游戏等场景不仅贡献了更高、更持续的算力需求，也提升了平台整体体验和终端用户活跃度。算力需求的上升进一步提高了算力节点被调用的频率和收益，使供需两端形成稳定的互相强化关系。
- 在算力供给增长和需求扩张的双轮推动下，代币在生态中的流通性和价值也不断增强。一方面，算力调用依赖稳定币支付；另一方面，使用者规模扩大与场景增多又提升了代币的市场交易量和认可度。代币价值上升反过来吸引了更多投资者进入生态。
- 投资者投入的资源会重新用于协议优化，支持技术优化和生态建设，如提升网络扩展性、优化激励结构，从而进一步增强算力提供者的收益能力并吸引更多算力加入网络。随着算力供应增加，算力价格逐步降低，更多应用开发者涌入生态，带来丰富算力使用场景和更高用户活跃度，驱动算力需求持续增长。算力使用量提升促进服务稳定性和用户体验升级，同时网络可信度增强，进一步吸引更多投资者投入资源。
- 最终形成“算力供给增加 → 算力价格降低 → 更多开发者涌入 → 用户体验升级 → 服务更稳定 → 网络可信度提升 → 生态更繁荣 → 用户活跃度提升 → 算力需求增加 → 平台持续扩展 → 代币流通与价值增长 → 市场信心倍增投资者进一步投入”的完整正向循环，推动 Vcity.ai 生态持续繁荣与代币价值稳步增长。

整体来看，这套机制使得算力供给端、需求端、代币价值与投资资源互相促进，带来市场活力和生态认可度的提升，为 Vcity.ai 的长期繁荣和可持续增长提供了动力。

### 3.5.2 网络协议层经济飞轮

Vcity.ai 的网络层经济模型构建了一个正向、自我强化的价值循环，即“网络层经济飞轮”。该飞轮将网络的外部增长转化为内生的、可持续的价值动力，确保生态长期繁荣。每个环节紧密衔接，互为因果，如上图所示。

- 网络增长：更多算力提供者和使用者加入网络，推动平台交易量和稳定币结算额增长。
- 协议收入：交易量提升直接增加协议收入。
- 价值捕获：协议收入的增长驱动了更大规模的 VCAI 市场回购。
- 权益回报：更大规模的回购提高 veVCAI 锁仓年化收益率（APR），增强长期持有和锁仓的吸引力。
- 治理强化：更高的收益激励 veVCAI 持有者积极参与治理，通过激励仪表盘将网络调节至最优供需平衡。
- 生态吸引力：供需平衡、成本结构合理且网络稳定可靠的生态吸引更多参与者加入，完成经济飞轮闭环，并推动下一轮网络增长。

## 3.6 VCAI代币价值保障策略

为确保VCAI代币价值的稳定性和长期增长潜力，平台实施了多维度的价值保障机制：

### 3.6.1 节点惩罚机制

为保障去中心化算力网络的稳定性与服务质量，平台引入基于链上行为的节点惩罚机制（包括算力节点和验证节点）：

- **违规行为识别**：智能合约自动监测节点的异常行为，如恶意宕机、提供虚假算力、篡改验证结果等。
- **分级惩罚措施**：

  - 轻微违规：扣除部分质押代币（5%-10%）
  - 中度违规：扣除较多质押代币（10%-30%）并暂停收益
  - 严重违规：没收全部质押代币并永久禁止参与网络
- **申诉机制**：设立公正的申诉渠道，由社区投票决定争议案例的最终处理。
- **用户补偿**：根据用户的实际使用情况，对受影响的算力部分提供足额补偿。

### 3.6.2 需求驱动价值增长

- **多元化应用场景**：通过AI训练、推理服务、实时渲染三大核心应用持续扩大算力需求市场，提高VCAI代币的实际使用需求。
- **生态协同效应**：与可信公链的去中心化身份（DID）、资产通证化、NFT等模块深度协同，构建完整的价值闭环。
- **合作伙伴拓展**：积极与AI企业、游戏开发商、元宇宙项目等建立战略合作，扩大代币应用范围。

## 3.7 动态供应模型

为确保协议在长期发展中保持激励的有效性和战略的灵活性，协议采用一种由治理控制的动态供应机制。此机制旨在将代币的增发权与网络基本面的健康度强绑定，确保任何供应量的增加都服务于生态系统的长期价值增长，并为协议提供应对未来机遇与挑战的必要机制设定。

### 3.7.1 动态供应授权

协议的动态供应能力并非一次性解锁，而是通过一个可累积的、基于持续增长的配额系统进行授权。DAO社区获得的战略提案配额，与网络在经济表现和社区长期承诺方面达成的阶梯式里程碑直接挂钩、共同作用，以证明协议已经获得了广泛且真实的用户基础，并且协议能够将用户转化为可持续的经济价值。

为此，协议会持续追踪以下两个核心增长指标：

- 协议收入指标：协议金库自创世以来累计捕获的稳定币净费用收入；
- 治理权益指标：网络中veVCAI代币的总量，即VCAI代币的锁仓量。

协议将以固定的阶梯来衡量增长：

- 协议收入阶梯：每200万美元累计净费用收入，计为一个"收入阶梯"；
- 治理权益阶梯：每5亿单位的veVCAI总量，计为一个"权益阶梯"。

DAO社区当前可用的动态供应提案配额数量，由以下公式决定：

<!-- $$
\text{可用的提案配额} = min(\text{已达成的收入阶梯数}, \text{已达成的权益阶梯数}) - \text{已执行的提案数量}
$$ -->

<Viewer imgUrl="/img/quotas-zh.png" />

 这一机制确保了协议的战略资本运作能力，始终与网络真实、均衡的持续增长保持同步，并受到年度供应上限的最终约束。需要注意的是，只有“战略增发”类型的提案会消耗此配额；“协议重定价”作为一种市值管理工具，不消耗配额。

### 3.7.2 治理流程

当增发能力被激活后，任何供应量的调整都必须遵循严谨的DAO治理决策流程。该流程包含提案、投票、以及一个旨在优化资本引入的融资模型。

- 提案：无论是战略增发还是协议重定价，任何相关提案都必须清晰地阐述其核心细节，包括但不限于：增发的战略目的、引入的合作伙伴、代币的分配方案、以及详细的锁仓和释放条款。其中，战略增发提案还必须明确声明其将消耗一个可用的提案配额。
- 投票：提案在经过充分的社区讨论（初步设定为1周）后，将进入正式的DAO治理投票环节。只有获得超过50% veVCAI持有者的投票支持，提案才会被批准执行。

### 3.7.3 动态供应机制

动态供应机制包括两类：战略增发与协议重定价。这类似于传统金融中的“拆股”与“融资”。

**战略增发：** 此提案旨在通过引入战略资本来加速网络发展。提案通过后，协议将额外铸造新的代币，根据融资提案的条款，定向分配给新的战略伙伴，即“定向增发”。这是一个明确的融资行为，其本质是用所有权比例的稀释来换取网络整体价值的更大增长。为提供可预测的供应模型，协议设定了年度增发上限：任何一年内，累计增发的代币总量，都不得超过该年年初总供应量的5%。

**协议重定价：** 此提案旨在优化代币的流动性和市场友好度，其效果类似于股票拆分，可作为重大融资或市场活动的预备步骤或独立操作。当提案通过时，协议将对代币面额进行一次全局重置。这是一个纯粹的市值管理工具，其在数学上是价值中性的。它不涉及任何新增代币的铸造，也不会对任何持有者的所有权比例产生稀释；其唯一目的是调整代币的记账单位。

# 四、技术架构核心竞争力

Vcity.ai通过如下创新的技术架构，力图在Web3 + AI领域建立了独特的竞争优势。

## 4.1 高效率的可信计算验证算法

在分布式计算网络中，由于缺乏链外的中央权威机构，因此如何确保链外计算过程的完整性与结果的正确性成为了一项基础性挑战。特别是在AI推理等信任敏感型场景中，确保其结果是由指定的输入和模型所产生是其核心需求。现有技术路线均无法很好地平衡通用性、安全性与效率这三个关键维度。

为此，我们构建一个轻量化的基于CPU TEE辅助验证GPU计算结果的通用框架。通过将GPU计算的元数据和执行度量捕获到可信执行环境中进行验证，无需特殊GPU硬件支持，从而提升Vcity.ai平台的可用算力资源规模；并以极低的性能开销，为GPU的计算任务提供高效、可靠的可信度证明。

## 4.2 分布式算力任务的弹性调度平台

当前需求侧的算力需求越发多样化与碎片化，覆盖从需要大规模集群长时间训练的重型任务，到仅需单卡短时推理或微调的轻型碎片化任务；同时还包括大规模并发的模型推理与通用计算任务（如金融仿真与科研模拟）。当前主流的算力供给模式（即集中式数据中心）在面对日益多样化的算力需求时，逐渐暴露出其结构偏向于服务高性能、大规模的异构算力集群，使得现有集中式算力供给模式显得刚性过剩而灵活性不足，难以实现资源的精确匹配与高效利用，从而造成显著的供需错配。与此同时，广泛分布于全球范围内的个人计算机、工作站及边缘设备中，存在大量未被充分利用的异构计算资源。这类资源具有数量庞大、接入灵活、维护成本低等特点。

为此我们构建一个分布式算力任务弹性调度平台。实现了整合异构、动态的闲置算力单元。并通过资源的统一抽象与管理，将其转化为可靠、易用且经济高效的计算服务。并根据任务需求与资源状态的约束关系，实现算力任务的自动、优化分配,从而减少资源闲置。

<!-- ![Vcity.ai技术解决方案架构](images/vcityai_tech.png) -->

<Viewer imgUrl="/img/vcityai_tech.png" />

# 五、商业模式核心竞争力

Vcity.ai通过创新的商业模式，在去中心化AI算力市场中建立了独特的竞争优势。平台针对不同参与方的痛点提供差异化价值主张，形成了完整的生态价值闭环。

## 5.1 AI使用者

Vcity.ai以去中心化架构整合全球GPU资源，为AI企业、AIGC开发者、文旅及元宇宙应用方提供兼具弹性、高性价比、垂类优化的智能算力基础设施，核心优势包括：

### 5.1.1 弹性调度、即开即用

- **全球化资源池**：构建覆盖北美、亚太、欧洲的分布式节点网络，实现跨地域资源调度，目标SLA为99.95%的服务可用性。
- **智能负载均衡**：基于AI预测的动态调度算法，实现毫秒级任务分配，支持突发性高并发需求。
- **零部署成本**：用户无需自建GPU集群和运维团队，通过Web界面或API即可快速接入高性能算力。

### 5.1.2 高性价比算力服务

- **成本优势明显**：相较于中心化云服务商，Vcity.ai可提供30%-70%的成本降幅，显著降低AI推理及训练成本。
- **灵活计费模式**：支持按时计费、按任务计费、包月包年等多种模式，满足不同规模用户需求。
- **无隐藏费用**：透明定价体系，无数据传输费、存储费等额外收费项目。

### 5.1.3 垂类大模型场景优化

- **行业专属优化**：针对文旅、元宇宙、AIGC等高增长行业，提供定制化算力加速方案。
- **预训练模型库**：内置行业专属大模型，如文旅知识问答模型、3D渲染优化模型、教育个性化推荐模型等。
- **一键部署模板**：提供场景化解决方案模板，包括AI教师、虚拟导游、智能客服等，实现快速业务落地。

### 5.1.4 智能合约托管，透明结算

- **链上执行保障**：全流程通过智能合约自动执行，确保算力调用、任务交付与费用结算的公开透明。
- **去信任化交易**：消除传统托管的信任风险，实现零人工干预的自动化结算。
- **实时审计追踪**：所有交易记录上链存证，支持全生命周期的审计和追溯。

### 5.1.5 智能体交易与变现通道

- **一站式发布平台**：支持AI模型的快速封装、测试、部署和商业化。
- **NFT确权保护**：通过NFT技术确保模型所有权和收益权，构建可信的数字资产体系。
- **AaaS生态**：形成开发者、使用者、投资者的多方共赢生态系统。

## 5.2 节点运营者

Vcity.ai为GPU拥有者、算力服务商及Web3节点运营者提供标准化接入、持续收益与链上治理的全栈运营体系，核心优势包括：

### 5.2.1 接入即收益，空闲也能变现

- **基础收益保障**：节点完成注册与质押后，即可获得基础PoC奖励，保证最低收益。
- **空闲资源变现**：GPU资源即便未被完全调用，仍可通过容量贡献获得持续收益。
- **收益计算透明**：基于链上数据实时计算收益，每日自动结算到账。

### 5.2.2 多重奖励模型，正向激励成长

- **三层激励体系**：

  - 容量证明（PoC）：基础硬件贡献奖励
  - 交付证明（PoD）：任务完成质量奖励
  - 服务费分润：实际算力使用费分成
- **长期激励机制**：设置节点忠诚度奖励、推荐奖励、绩效奖金等额外激励。

### 5.2.3 低门槛部署，智能调度与链上结算

- **一键部署工具**：提供Docker容器镜像和自动化部署脚本，30分钟内完成节点上线。
- **自动化结算**：所有任务分配与奖励发放通过智能合约自动执行，无需人工干预。

### 5.2.4 去中心化治理权与声誉机制

- **链上身份系统**：每个节点拥有唯一的DID标识，记录完整服务历史。
- **声誉评分体系**：基于服务质量、在线时长、任务完成率等多维度构建声誉分数。
- **治理参与权**：高声誉节点可参与网络参数调整、升级决策等重要治理事项。

## 5.3 投资人

Vcity.ai作为基于可信公链构建的去中心化AI算力网络与垂类应用平台，具备显著的资本吸引力与增长潜力，核心优势包括：

### 5.3.1 高增长赛道红利叠加

- **双重趋势交汇**：抢占GenAI（预计2030年市场规模1.3万亿美元）与DePIN双重风口。
- **市场需求爆发**：受益于全球GPU供需失衡（缺口超40%）和AI模型训练需求指数级增长。
- **政策支持明确**：多国政府出台AI发展战略，算力基础设施获得政策和资金重点支持。

### 5.3.2 双轮驱动商业模式

- **B端市场覆盖**：

  - 目标客户：AI企业、文旅集团、教育机构、政府部门
  - 市场规模：仅中国AI算力市场2025年预计超500亿美元
- **C端市场拓展**：

  - 目标用户：AIGC创作者、独立开发者、中小企业
  - 用户基数大：全球AI开发者超2000万
  - 增长潜力强：据行业报告，AIGC用户年增长率在近年显著提升（部分细分赛道超过200%）
- **多元收入来源**：算力租赁、平台服务费、交易佣金、增值服务。

### 5.3.3 基于原生代币的价值支撑

- **多功能代币设计**：VCAI代币集节点质押、治理投票、生态激励于一体，形成强需求支撑。
- **回购机制保障**：定期回购，确保长期价值稳定上升。
- **金融创新空间**：支持质押挖矿、流动性挖矿、合成资产等去中心化金融（Decentralized Finance, DeFi）创新应用。

### 5.3.4 真实资产锚定与竞争壁垒

- **实体资产背书**：所有算力基于真实GPU硬件，形成实物资产与数字资产的价值锚定。
- **网络效应护城河**：节点数量越多，网络价值呈指数级增长（梅特卡夫定律）。
- **技术壁垒深厚**：自研调度算法、跨链协议、隐私计算等核心技术。

# 六、商业模式

Vcity.ai平台构建了多元化的收入模式，通过算力服务、网络运营、定制化解决方案及智能体服务四大核心板块，实现可持续的商业价值创造。

## 6.1 算力租赁服务

- **按需付费模式**：算力使用者（包括AI企业、元宇宙平台、文旅企业等）根据实际使用的GPU资源量和计算时长，支付相应的算力租赁费用。
- **动态定价机制**：平台根据资源等级、节点质量、算力规模等多维度因素，实施灵活的差异化定价策略，确保资源配置效率最大化。

## 6.2 网络服务手续费

- **交易手续费**：Vcity.ai平台对用户的每笔算力交易收取一定比例的网络服务手续费，作为平台运营的基础收入。
- **动态调节机制**：手续费标准基于市场供需动态调节，所有费用透明公开且实现实时结算，保障交易公平性。

## 6.3 企业定制化服务

针对文旅、元宇宙等垂直行业的特定需求，平台提供专属的AI大模型训练与优化服务，通过深度定制化解决方案，收取相应的技术服务费用，为企业数字化转型提供强力支撑。

**智能体即服务：**

- **创建收费**：每个AI智能体的创建过程收取基础服务费，同时包含NFT铸造所需的Gas费用。
- **交易佣金**：在二级市场的智能体交易中，平台抽取固定比例的交易手续费。
- **调用分润**：当智能体被接入网页或元宇宙场景时，按调用次数或使用时长收费，收益由智能体创建者/持有者与平台按约定比例分润。

# 七、发展规划与里程碑

Vcity.ai制定了清晰的三年发展战略，通过阶段性目标的逐步达成，致力于构建全球领先的去中心化AI基础设施平台。

## 7.1 第一阶段：技术验证与生态启动

### 7.1.1 核心目标

- 完成核心技术架构搭建和最小可行产品（MVP）开发
- 验证核心功能的可行性、稳定性和扩展性

### 7.1.2 关键里程碑

- **技术开发成果**：

  - 完成VCAI代币智能合约的开发、测试和第三方安全审计
  - 发布算力节点v1.0版本，支持基础算力接入功能
  - 完成P2P网络层架构和基础任务调度算法的实现
- **测试网络部署**：

  - 成功部署Vcity.ai测试网络环境
  - 开放开发者内测计划，收集反馈并持续优化系统性能
  - 完成首批企业级客户的概念验证（POC）测试
- **团队与社群建设**：

  - 创建早期节点运营者社群，形成核心用户群体
  - 制定社群治理规则和运营标准

## 7.2 第二阶段：规模扩张与产品成熟

### 7.2.1 核心目标

- 实现主网正式上线并达到规模化运营水平
- 建立完整的产品矩阵和多层次服务体系
- 全面启动代币经济激励体系

### 7.2.2 关键里程碑

- **主网正式启动**：

  - 完成验证节点与调度节点的设计开发，并逐步接入主网运行
  - 部署VCAI主网激励机制，正式上线首次接入奖励、佣金分配和长期分润系统
  - 将经过充分测试验证的算力节点管理、任务调度等核心智能合约迁移至主网环境
- **AI解决方案平台发布**：

  - 面向文旅、教育、博物馆等文化领域，构建集内容创作、智能交互、知识传播与文化资产数字化于一体的综合性AI应用服务平台
  - 提供标准化API接口和定制化解决方案，降低企业AI应用门槛
  - 建立行业标杆案例，形成可复制的商业模式
- **市场拓展**：

  - 实现多区域节点部署，提升网络覆盖度和服务可用性
  - 建立战略合作伙伴体系，深化产业生态合作

## 7.3 第三阶段：生态成熟与领导地位确立

### 7.3.1 核心目标

- 确立全球品牌影响力，实现商业模式成熟与可持续盈利
- 构建完整的AI算力生态系统与跨行业解决方案平台
- 实现财务盈亏平衡并保持持续盈利能力

### 7.3.2 关键里程碑

- **AI算力综合服务平台升级**：

  - 提供企业级GPU训练和推理算力的弹性分配服务，支持LoRA微调、AIGC内容生成、实时云渲染等多样化工作负载
  - 支持开发者创建、托管、铸造和交易AI智能体NFT（涵盖文旅数字人、AI助手、教育智能体等应用场景），实现AaaS的价值共享与商业变现
  - 建立算力资源的智能调度和优化系统，实现资源利用率最大化
- **全球生态体系建设**：

  - 建立完整的开发者支持中心与开放API生态门户，提供全方位技术支持
  - 打造全球化算力服务品牌，积极参与国际AI和Web3行业高峰论坛
  - 推动行业标准制定，引领去中心化AI基础设施发展方向
  - 实现全球主要区域的业务覆盖，建立国际化运营体系
